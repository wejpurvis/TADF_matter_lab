{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting S1 & T1 Energies\n",
    "\n",
    "In this notebook, the model run on the supercomputer is loaded and used to predict S1 and T1 excited state energies in TADF molecules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2613c534c50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 23\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFDataset(Dataset):\n",
    "\n",
    "    def __init__(self, fn, length = None):\n",
    "        # Data Loading\n",
    "        loaded_data = pd.read_csv(fn, sep =\"\\t\", header=None)\n",
    "        all_data = loaded_data[:length]\n",
    "        self.data = all_data #Return all data as dataframe\n",
    "\n",
    "        #Manipulate data using Pandas & RDkit\n",
    "        all_data.columns = [\"ID\", \"SMILES\",\"LUMO\", \"HOMO\", \"E(S1)\", \"E(T1)\"]\n",
    "        filt_data = all_data.drop(columns = [\"ID\", \"LUMO\", \"HOMO\"])\n",
    "        filt_data[\"MOL\"] = filt_data[\"SMILES\"].apply(lambda x: Chem.MolFromSmiles(x)) #Add column of Molecular objects\n",
    "\n",
    "        def calculate_MFP(molecule):\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(molecule, 3, nBits=1024)\n",
    "            nf = fp.ToList()\n",
    "            return nf\n",
    "        \n",
    "        filt_data[\"MFP\"] = filt_data[\"MOL\"].apply(calculate_MFP)\n",
    "\n",
    "        mfps = np.array(filt_data[\"MFP\"].tolist())\n",
    "        #e_s1 = np.array(filt_data[\"E(S1)\"])\n",
    "        #e_t1 = np.array(filt_data[\"E(T1)\"])\n",
    "\n",
    "        energies = np.column_stack((filt_data[\"E(S1)\"], filt_data[\"E(T1)\"]))\n",
    "        \n",
    "        self.mfps = mfps #Vector of Morgan fingerprints (X by 1024)\n",
    "        self.energies = energies # Matrix of S1 & T1 energies(X by 2)\n",
    "        self.n_samples = filt_data.shape[0] #number of data_points\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # dataset[0]\n",
    "\n",
    "        return self.mfps[index], self.energies[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Length of Dataset\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/TADF_data_DL.txt\" #location of data\n",
    "\n",
    "full_dataset = MFDataset(path)\n",
    "\n",
    "#Splitting dataset 8:1:1\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.8*total_size)\n",
    "validation_size = int(0.1*total_size)\n",
    "test_size = total_size - (train_size + validation_size)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, validation_size, test_size])\n",
    "\n",
    "#Create DataLoaders for training, validation, & testing\n",
    "bs = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = bs, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = bs, shuffle = False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = bs, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layers building block\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature, dropout):\n",
    "        super().__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.dropout = dropout\n",
    "        self.Linear=nn.Linear(in_feature,out_feature)\n",
    "        self.dropout = nn.Dropout(p=self.dropout)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_x = x\n",
    "        x = self.Linear(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x+skip_x\n",
    "        x = self.activation(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "#Fingerprint MLP model\n",
    "class FpMLP(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(FpMLP, self).__init__()\n",
    "\n",
    "        # Argument Define\n",
    "        self.dim_of_fp = args[\"fp_dim\"]\n",
    "        self.dim_of_Linear = args[\"hidden_dim\"]\n",
    "\n",
    "        self.N_predict_layer = args[\"N_MLP_layer\"]\n",
    "        self.N_predict_FC = args[\"N_predictor_layer\"]\n",
    "\n",
    "        self.N_properties = args[\"N_properties\"]\n",
    "\n",
    "        self.dropout = args[\"dropout\"]\n",
    "\n",
    "        self.embedding=nn.Linear(self.dim_of_fp,self.dim_of_Linear)\n",
    "\n",
    "        self.MLPs= nn.ModuleList([\n",
    "            MLP(self.dim_of_Linear,self.dim_of_Linear,self.dropout) for _ in range(self.N_predict_layer)])\n",
    "\n",
    "        self.predict = \\\n",
    "            nn.ModuleList([\n",
    "                nn.Sequential(nn.Linear(self.dim_of_Linear,self.dim_of_Linear),\n",
    "                              nn.Dropout(p=self.dropout),\n",
    "                              nn.ReLU())\n",
    "                for _ in range(self.N_predict_FC-1)] +\n",
    "                [nn.Linear(self.dim_of_Linear,self.N_properties)\n",
    "            ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        for layer in self.MLPs:\n",
    "            x = layer(x)\n",
    "\n",
    "        for layer in self.predict:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation Loop\n",
    "#Similar to training loop but gradients are not calculated (with torch.no_grad() uses less memory)\n",
    "def evaluate(model, iterator, loss_funct):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    r2_score = 0\n",
    "    model.eval()\n",
    "\n",
    "    maes = 0\n",
    "    mses = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=True):\n",
    "            x = x.to(torch.float32) #MFP\n",
    "            y = y.to(torch.float32) #S1 & T1 energies\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = loss_funct(y_pred, y)\n",
    "\n",
    "            mae = mean_absolute_error(y.numpy(), y_pred.numpy())\n",
    "            maes += mae\n",
    "\n",
    "            mse = mean_squared_error(y.numpy(), y_pred.numpy())\n",
    "            mses += mse\n",
    "\n",
    "            r2 = R2Score()\n",
    "            r2.update(y_pred,y)\n",
    "            r2_score += float(r2.compute())\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), r2_score / len(iterator), maes / len(iterator), mses / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model and its configurations (hyperparemeters, loss function, & learning rate) are loaded using the function below. The configurations used in training the model are also displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fp_dim': 1024,\n",
       " 'hidden_dim': 1869,\n",
       " 'N_MLP_layer': 7,\n",
       " 'N_predictor_layer': 1,\n",
       " 'N_properties': 2,\n",
       " 'dropout': 0,\n",
       " 'learning_rate': 0.0003108135902739477,\n",
       " 'criterion': SmoothL1Loss()}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_model(filename):\n",
    "    checkpoint = torch.load(filename)\n",
    "    config = checkpoint[\"config\"]\n",
    "    \n",
    "    # Create an instance of your model using the configuration\n",
    "    model = FpMLP(config)\n",
    "    \n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    \n",
    "    return model, config\n",
    "\n",
    "loaded_model, config = load_model(\"./models/model_4.pt\")\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 132/132 [00:05<00:00, 23.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss on test set:  0.0685\n",
      "MSE on test set:  0.1415\n",
      "MAE on test set:  0.2706\n",
      "R2 score on test set:  0.6208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_r2, test_mae, test_mse = evaluate(loaded_model, test_dataloader, config[\"criterion\"])\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Loss on test set:  {test_loss:.4f}\")\n",
    "print(f\"MSE on test set:  {test_mse:.4f}\")\n",
    "print(f\"MAE on test set:  {test_mae:.4f}\")\n",
    "print(f\"R2 score on test set:  {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model, trained using the same configurations as in the literature, achieves an MAE score of 0.2706 eV on the test set. To showcase model performance of a specific molecule, the following code can be employed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Energies: [3.4666114 2.7837038]\n",
      "Actual Energies:  [3.416  2.8756]\n"
     ]
    }
   ],
   "source": [
    "data_1_x = test_dataset[0][0] #First test MFP\n",
    "data_1_x = torch.tensor(data_1_x, dtype = torch.float32) #Convert to tensor of appropriate data type\n",
    "\n",
    "# Pass the input feature through the model to get the predicted output\n",
    "with torch.no_grad():\n",
    "    predicted_output = loaded_model(data_1_x.unsqueeze(0))  # Unsqueeze to add batch dimension\n",
    "\n",
    "# You can now use the predicted output for further analysis or comparison\n",
    "print(\"Predicted Energies:\", predicted_output.numpy().flatten())\n",
    "print(\"Actual Energies: \", test_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2aa9cdcc63ea380134092a280d164913100487c8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
