{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer perceptron models on OLED features\n",
    "This notebook uses MLP models to predict various OLED properties. Properties of interest are:\n",
    "1. Absorption max /nm\n",
    "2. Emission max /nm\n",
    "3. Lifetime /ns\n",
    "4. Quantum yield (PLQY)\n",
    "5. Absorption full width at half maximum (FWHM) /cm<sup>-1</sup>\n",
    "6. Emission full width at half maximum (FWHM) /cm<sup>-1</sup>  \n",
    "\n",
    "The dataset was taken from DOI: [10.1021/jacsau.1c00035](https://pubs.acs.org/doi/10.1021/jacsau.1c00035)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "\n",
    "#Load data and remove unwanted chromophores\n",
    "smi = pd.read_csv('./data/OLED_dataset_CSV.csv', encoding='windows-1252') # load csv file (20236, 14)\n",
    "\n",
    "target_atom = ['Sn']\n",
    "Unnecessary_chromophores = []\n",
    "\n",
    "smi[\"Molecules\"] = smi[\"Chromophore\"].apply(lambda x: Chem.MolFromSmiles(x)) #Add column of Molecular objects\n",
    "\n",
    "for _, row in smi.iterrows():\n",
    "    atoms = {atom.GetSymbol() for atom in row[\"Molecules\"].GetAtoms()}\n",
    "    if set(target_atom).intersection(atoms):\n",
    "        Unnecessary_chromophores.append(row[\"Chromophore\"])\n",
    "\n",
    "\n",
    "filtered_smi = smi[~smi['Chromophore'].isin(Unnecessary_chromophores)]\n",
    "\n",
    "#Create dictionary of SMILES: Morgan fingerprint\n",
    "\n",
    "Mfp_Chrom = {}\n",
    "\n",
    "for _, row in filtered_smi.iterrows():\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(row[\"Molecules\"], 3, nBits=1024)\n",
    "    nf = np.array(fp).tolist()\n",
    "    Mfp_Chrom[row[\"Chromophore\"]] = nf\n",
    "\n",
    "#Get Unique Solvents\n",
    "filtered_smi = filtered_smi[filtered_smi.Solvent != \"gas\"] #remove \"gas\" from solvents\n",
    "filtered_smi_sol = filtered_smi.drop_duplicates(subset=[\"Solvent\"]) #remove duplicates from solvents\n",
    "\n",
    "\n",
    "#Create dictionary of SMILES: Morgan fingerprint (solvents)\n",
    "\n",
    "Mfp_Sol = {}\n",
    "\n",
    "for _, row in filtered_smi_sol.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row[\"Solvent\"])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 3, nBits=1024)\n",
    "    nf = np.array(fp).tolist()\n",
    "    Mfp_Sol[row[\"Solvent\"]] = nf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define inputs given feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processed(ft, print_size=False):\n",
    "    oled_dropped = filtered_smi.dropna(subset=ft,axis=0)\n",
    "\n",
    "    #Building MF arrays of chromophores and solvents from oled_dropped\n",
    "    chromophore = [] \n",
    "    solvent = [] \n",
    "    mw = [] \n",
    "\n",
    "    for _, row in oled_dropped.iterrows():\n",
    "        chromophore.append(Mfp_Chrom[row[\"Chromophore\"]])\n",
    "        solvent.append(Mfp_Sol[row[\"Solvent\"]])\n",
    "        mw.append(row[\"Molecular weight (g mol-1)\"])\n",
    "\n",
    "    chromophore_reshaped = np.reshape(chromophore, (-1, 1024))\n",
    "    solvent_reshaped = np.reshape(solvent, (-1, 1024))\n",
    "    mw_reshaped = np.reshape(mw, (-1,1))\n",
    "\n",
    "    #Concatenate MFPs\n",
    "    a = np.concatenate((chromophore_reshaped, solvent_reshaped), axis = 1) # (17275, 2048) matrix of chromophore & solvent MFPs\n",
    "    b = np.concatenate((a, mw_reshaped), axis = 1) # (17275, 2049) matrix of MFPs & mws\n",
    "\n",
    "    #Define inputs & features\n",
    "    X = b\n",
    "    Y = np.reshape(oled_dropped[ft], (-1,1))\n",
    "\n",
    "    if print_size:\n",
    "        print(\"Data points before preprocessing \", len(smi))\n",
    "        print(\"Data points after preprocessing \", len(oled_dropped))\n",
    "\n",
    "    else:\n",
    "        return X, Y, len(oled_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP models\n",
    "#### Required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "\n",
    "#Evaluate models\n",
    "def model_eval(y_test, y_pred, print_res=True):\n",
    "    # R2 Score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    # MAE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    # MSE\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    if print_res:\n",
    "        print('R2 score: ', r2)\n",
    "        print('MAE: ', mae)\n",
    "        print('MSE: ', mse)\n",
    "\n",
    "    else:\n",
    "        return r2, mae, mse\n",
    "    \n",
    "#Split data into training & test sets & standardise after split to avoid data leakage\n",
    "def split_standard_transform(inputs, features, state):\n",
    "    #Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(inputs, features, test_size=0.1, random_state=state)\n",
    "\n",
    "    # X has format [---MFP of Chromophore---][---MFP of Solvent---][MW]\n",
    "    # MFPs are binary -> only standardize MW\n",
    "    scaler_X = StandardScaler().fit(np.array([X_train[:,-1]]).T) #fit scaler to training mws\n",
    "\n",
    "    X_mw_train_standardized = scaler_X.transform(np.array([X_train[:,-1]]).T) #standardize to training mw\n",
    "    X_train_standardized = np.concatenate((X_train[:, :-1], X_mw_train_standardized), axis=1) #add standardized training mw to training MFPs\n",
    "\n",
    "    X_mw_test_standardized = scaler_X.transform(np.array([X_test[:,-1]]).T) #standardize test mw\n",
    "    X_test_standardized = np.concatenate((X_test[:, :-1], X_mw_test_standardized), axis=1) #add standardized test mw to testing MFPs\n",
    "\n",
    "    pt = PowerTransformer(standardize = True).fit(y_train)\n",
    "    y_train_transformed = pt.transform(y_train).ravel()\n",
    "    y_test_transformed = pt.transform(y_test).ravel()\n",
    "\n",
    "    return X_train_standardized, X_test_standardized, y_train_transformed, y_test_transformed\n",
    "\n",
    "# X_train, X_test, y_train, y_test = split_standard_transform(X, Y, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature = Absorption max /nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points before preprocessing  20236\n",
      "Data points after preprocessing  17275\n"
     ]
    }
   ],
   "source": [
    "feature = \"Absorption max (nm)\"\n",
    "data_processed(feature, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score:  0.9424571904867128\n",
      "MAE:  0.14246132189188312\n",
      "MSE:  0.0585926777760493\n"
     ]
    }
   ],
   "source": [
    "X, Y,_ = data_processed(feature)\n",
    "X_train, X_test, y_train, y_test = split_standard_transform(X, Y, 42)\n",
    "\n",
    "MLP = MLPRegressor(hidden_layer_sizes=(100,), max_iter = 200, random_state=23)\n",
    "MLP.fit(X_train, y_train)\n",
    "\n",
    "y_pred = MLP.predict(X_test)\n",
    "model_eval(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature = Emission max /nm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points before preprocessing  20236\n",
      "Data points after preprocessing  18140\n"
     ]
    }
   ],
   "source": [
    "feature2 = \"Emission max (nm)\"\n",
    "data_processed(feature2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score:  0.9082105164000472\n",
      "MAE:  0.20119742627519246\n",
      "MSE:  0.09138516832704399\n"
     ]
    }
   ],
   "source": [
    "X2, Y2,_  = data_processed(feature2)\n",
    "X_train2, X_test2, y_train2, y_test2 = split_standard_transform(X2, Y2, 42)\n",
    "\n",
    "MLP = MLPRegressor(hidden_layer_sizes=(100,), max_iter = 200, random_state=23)\n",
    "MLP.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred2 = MLP.predict(X_test2)\n",
    "model_eval(y_test2, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature = Lifetime /ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points before preprocessing  20236\n",
      "Data points after preprocessing  6960\n"
     ]
    }
   ],
   "source": [
    "feature3 = \"Lifetime (ns)\"\n",
    "data_processed(feature3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score:  0.7309199256261549\n",
      "MAE:  0.35456538524992137\n",
      "MSE:  0.26857598480407574\n"
     ]
    }
   ],
   "source": [
    "X3, Y3,_  = data_processed(feature3)\n",
    "X_train3, X_test3, y_train3, y_test3 = split_standard_transform(X3, Y3, 42)\n",
    "\n",
    "MLP = MLPRegressor(hidden_layer_sizes=(100,), max_iter = 200, random_state=23)\n",
    "MLP.fit(X_train3, y_train3)\n",
    "\n",
    "y_pred3 = MLP.predict(X_test3)\n",
    "model_eval(y_test3, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature = Quantum yield (PLQY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points before preprocessing  20236\n",
      "Data points after preprocessing  13836\n"
     ]
    }
   ],
   "source": [
    "feature4 = \"Quantum yield\"\n",
    "data_processed(feature4, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score:  0.6934420183128704\n",
      "MAE:  0.4054639654273137\n",
      "MSE:  0.31489363994065556\n"
     ]
    }
   ],
   "source": [
    "X4, Y4,_  = data_processed(feature4)\n",
    "X_train4, X_test4, y_train4, y_test4 = split_standard_transform(X4, Y4, 42)\n",
    "\n",
    "MLP = MLPRegressor(hidden_layer_sizes=(100,), max_iter = 200, random_state=23)\n",
    "MLP.fit(X_train4, y_train4)\n",
    "\n",
    "y_pred4 = MLP.predict(X_test4)\n",
    "model_eval(y_test4, y_pred4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature = Absorption FWHM /cm<sup>-1</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points before preprocessing  20236\n",
      "Data points after preprocessing  3588\n"
     ]
    }
   ],
   "source": [
    "feature5 = \"abs FWHM (nm)\"\n",
    "data_processed(feature5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score:  0.6934420183128704\n",
      "MAE:  0.4054639654273137\n",
      "MSE:  0.31489363994065556\n"
     ]
    }
   ],
   "source": [
    "X5, Y5,_  = data_processed(feature4)\n",
    "X_train5, X_test5, y_train5, y_test5 = split_standard_transform(X5, Y5, 42)\n",
    "\n",
    "MLP = MLPRegressor(hidden_layer_sizes=(100,), max_iter = 200, random_state=23)\n",
    "MLP.fit(X_train5, y_train5)\n",
    "\n",
    "y_pred5 = MLP.predict(X_test5)\n",
    "model_eval(y_test5, y_pred5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature = Emission FWHM /cm<sup>-1</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points before preprocessing  20236\n",
      "Data points after preprocessing  7197\n"
     ]
    }
   ],
   "source": [
    "feature6 = \"emi FWHM (nm)\"\n",
    "data_processed(feature6, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score:  0.6929802861128018\n",
      "MAE:  0.36590055094832336\n",
      "MSE:  0.2922739404477624\n"
     ]
    }
   ],
   "source": [
    "X6, Y6,_  = data_processed(feature6)\n",
    "X_train6, X_test6, y_train6, y_test6 = split_standard_transform(X6, Y6, 42)\n",
    "\n",
    "MLP = MLPRegressor(hidden_layer_sizes=(100,), max_iter = 200, random_state=23)\n",
    "MLP.fit(X_train6, y_train6)\n",
    "\n",
    "y_pred6 = MLP.predict(X_test6)\n",
    "model_eval(y_test6, y_pred6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Model to all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Absorption max (nm)', 'Emission max (nm)', 'Lifetime (ns)', 'Quantum yield', 'abs FWHM (nm)', 'emi FWHM (nm)']\n",
    "\n",
    "mlp_res = {}\n",
    "\n",
    "for feat in features:\n",
    "    X, Y, data_points = data_processed(feat)\n",
    "    X_train, X_test, y_train, y_test = split_standard_transform(X, Y, 42)\n",
    "\n",
    "    MLP = MLPRegressor(hidden_layer_sizes=(100,), max_iter = 200, random_state=23)\n",
    "    MLP.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = MLP.predict(X_test)\n",
    "    r2, mae, mse = model_eval(y_test, y_pred, print_res = False)\n",
    "    mlp_res[feat] = (r2, mae, mse, data_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absorption max (nm)</th>\n",
       "      <th>Emission max (nm)</th>\n",
       "      <th>Lifetime (ns)</th>\n",
       "      <th>Quantum yield</th>\n",
       "      <th>abs FWHM (nm)</th>\n",
       "      <th>emi FWHM (nm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R2 Score</th>\n",
       "      <td>0.942457</td>\n",
       "      <td>0.908211</td>\n",
       "      <td>0.730920</td>\n",
       "      <td>0.693442</td>\n",
       "      <td>0.791628</td>\n",
       "      <td>0.692980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.142461</td>\n",
       "      <td>0.201197</td>\n",
       "      <td>0.354565</td>\n",
       "      <td>0.405464</td>\n",
       "      <td>0.279734</td>\n",
       "      <td>0.365901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.058593</td>\n",
       "      <td>0.091385</td>\n",
       "      <td>0.268576</td>\n",
       "      <td>0.314894</td>\n",
       "      <td>0.200608</td>\n",
       "      <td>0.292274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>17275.000000</td>\n",
       "      <td>18140.000000</td>\n",
       "      <td>6960.000000</td>\n",
       "      <td>13836.000000</td>\n",
       "      <td>3588.000000</td>\n",
       "      <td>7197.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Absorption max (nm)  Emission max (nm)  Lifetime (ns)  \\\n",
       "R2 Score             0.942457           0.908211       0.730920   \n",
       "MAE                  0.142461           0.201197       0.354565   \n",
       "MSE                  0.058593           0.091385       0.268576   \n",
       "N                17275.000000       18140.000000    6960.000000   \n",
       "\n",
       "          Quantum yield  abs FWHM (nm)  emi FWHM (nm)  \n",
       "R2 Score       0.693442       0.791628       0.692980  \n",
       "MAE            0.405464       0.279734       0.365901  \n",
       "MSE            0.314894       0.200608       0.292274  \n",
       "N          13836.000000    3588.000000    7197.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_table = pd.DataFrame.from_dict(mlp_res)\n",
    "rows = [\"R2 Score\", \"MAE\", \"MSE\", \"N\"]\n",
    "results_table.index = rows\n",
    "\n",
    "results_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
